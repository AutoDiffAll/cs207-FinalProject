{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from variables import Variable\n",
    "except:\n",
    "    from AutoDiff.variables import Variable\n",
    "try:\n",
    "    from vectorize_func import vectorize_variable\n",
    "except:\n",
    "    from AutoDiff.vectorize_func import vectorize_variable\n",
    "try:\n",
    "    import AD_numpy as anp\n",
    "except:\n",
    "    import AutoDiff.AD_numpy as anp\n",
    "    \n",
    "try:\n",
    "    import Optimizer as op\n",
    "except:\n",
    "    import AutoDiff.Optimizer as op\n",
    "import numpy as np\n",
    "from numpy.linalg import pinv\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.85 2.04 4.9 ]\n",
      "[2.77561411 2.079168   4.8118    ]\n",
      "[2.72539004 2.11745929 4.73367562]\n",
      "[2.6876602  2.15483417 4.66421597]\n",
      "[2.65761051 2.19125801 4.60225503]\n",
      "[2.63275994 2.22670126 4.54682041]\n",
      "[2.61165728 2.26113937 4.49709452]\n",
      "[2.5933797 2.2945527 4.4523849]\n",
      "[2.57730411 2.32692642 4.41210107]\n",
      "[2.56299033 2.35825028 4.37573644]\n",
      "[2.55011612 2.38851841 4.34285397]\n",
      "[2.53843869 2.41772911 4.31307467]\n",
      "[2.52777072 2.44588457 4.28606838]\n",
      "[2.51796479 2.47299062 4.26154621]\n",
      "[2.50890286 2.49905641 4.23925438]\n",
      "[2.50048903 2.52409413 4.21896918]\n",
      "[2.49264439 2.54811876 4.2004927 ]\n",
      "[2.48530323 2.5711477  4.18364933]\n",
      "[2.47841033 2.59320055 4.16828285]\n",
      "[2.47191883 2.6142988  4.15425384]\n",
      "[2.46578864 2.63446556 4.14143764]\n",
      "[2.45998526 2.65372532 4.12972254]\n",
      "[2.45447873 2.67210368 4.11900818]\n",
      "[2.44924292 2.68962714 4.10920426]\n",
      "[2.44425492 2.70632288 4.10022941]\n",
      "[2.43949449 2.72221859 4.09201014]\n",
      "[2.43494374 2.73734222 4.08448001]\n",
      "[2.4305867  2.75172191 4.07757887]\n",
      "[2.42640913 2.76538575 4.07125219]\n",
      "[2.42239825 2.77836173 4.06545048]\n",
      "[2.41854254 2.79067755 4.06012877]\n",
      "[2.41483162 2.80236058 4.05524616]\n",
      "[2.41125606 2.81343772 4.05076542]\n",
      "[2.4078073  2.82393535 4.04665265]\n",
      "[2.40447755 2.83387925 4.0428769 ]\n",
      "[2.40125968 2.84329458 4.03940998]\n",
      "[2.39814717 2.85220577 4.03622612]\n",
      "[2.39513402 2.86063656 4.03330179]\n",
      "[2.39221473 2.86860992 4.03061546]\n",
      "[2.38938421 2.87614806 4.02814748]\n",
      "[2.38663777 2.88327239 4.02587984]\n",
      "[2.38397108 2.89000354 4.02379605]\n",
      "[2.38138009 2.89636134 4.02188104]\n",
      "[2.37886108 2.90236484 4.02012098]\n",
      "[2.37641055 2.9080323  4.01850321]\n",
      "[2.37402528 2.9133812  4.0170161 ]\n",
      "[2.37170222 2.91842827 4.01564903]\n",
      "[2.36943857 2.9231895  4.01439221]\n",
      "[2.36723166 2.92768013 4.01323669]\n",
      "[2.36507902 2.93191472 4.01217425]\n",
      "[2.36297832 2.93590712 4.01119734]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Optimizer.Result at 0x181d6300dd8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x, y, z: (x-2)**5 + (y-3)**2 + (z-4)**2\n",
    "#op.minimize(f, [3, 2, 1], method=\"Newton Method\")\n",
    "op.min_gradientdescent(f, [3, 2, 5], 1e-6, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.94  2.142 4.9  ]\n",
      "[2.995272   2.11208933 4.9882    ]\n",
      "[2.93564979 2.24974101 4.88961322]\n",
      "[2.9905846  2.23214133 4.97661051]\n",
      "[2.93133605 2.3625136  4.8794063 ]\n",
      "[2.98593723 2.36035281 4.96522592]\n",
      "[2.9270583  2.48064489 4.86937462]\n",
      "[2.98132937 2.4968972  4.95404084]\n",
      "[2.92281605 2.60510284 4.85951369]\n",
      "[2.97676048 2.64231349 4.94305006]\n",
      "[2.91860884 2.73853412 4.84981919]\n",
      "[2.97223004 2.79891812 4.93224858]\n",
      "[2.91443621 2.88902826 4.84028694]\n",
      "[2.96773753 2.97958274 4.92163154]\n",
      "[2.91029771 2.96239976 4.83091292]\n",
      "[2.96328246 2.99386131 4.91119428]\n",
      "[2.9061929  2.98867028 4.82169324]\n",
      "[2.95886433 2.99823435 4.9009323 ]\n",
      "[2.90212134 2.9967391  4.81262413]\n",
      "[2.95448265 2.99949925 4.89084122]\n",
      "[2.8980826  2.999075   4.80370196]\n",
      "[2.95013695 2.99985856 4.88091686]\n",
      "[2.89407627 2.99973872 4.79492322]\n",
      "[2.94582677 2.9999601  4.87115513]\n",
      "[2.89010193 2.99992629 4.7862845 ]\n",
      "[2.94155164 2.99998875 4.86155212]\n",
      "[2.88615918 2.99997921 4.77778251]\n",
      "[2.93731111 2.99999683 4.85210403]\n",
      "[2.88224763 2.99999414 4.76941408]\n",
      "[2.93310475 2.99999911 4.84280717]\n",
      "[2.87836687 2.99999835 4.76117611]\n",
      "[2.92893211 2.99999975 4.83365798]\n",
      "[2.87451653 2.99999953 4.75306563]\n",
      "[2.92479277 2.99999993 4.82465304]\n",
      "[2.87069623 2.99999987 4.74507974]\n",
      "[2.92068632 2.99999998 4.815789  ]\n",
      "[2.8669056  2.99999996 4.73721565]\n",
      "[2.91661233 2.99999999 4.80706264]\n",
      "[2.86314427 2.99999999 4.72947062]\n",
      "[2.9125704  3.         4.79847082]\n",
      "[2.85941189 3.         4.72184204]\n",
      "[2.90856015 3.         4.79001052]\n",
      "[2.85570811 3.         4.71432735]\n",
      "[2.90458116 3.         4.78167881]\n",
      "[2.85203257 3.         4.70692407]\n",
      "[2.90063307 3.         4.77347283]\n",
      "[2.84838494 3.         4.6996298 ]\n",
      "[2.89671548 3.         4.76538982]\n",
      "[2.84476489 3.         4.6924422 ]\n",
      "[2.89282804 3.         4.7574271 ]\n",
      "[2.84117208 3.         4.68535902]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Optimizer.Result at 0x181d630e160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return (x[0]-2)**2 + (x[1]-3)**2 + (x[2]-4)**2\n",
    "op.min_steepestdescent(f, [3, 2, 5], 1e-6, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 68\n",
      "         Function evaluations: 124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.00002227, 3.00002265, 3.99997193])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import fmin\n",
    "fmin(f, [3,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gradientdescent(fn, x0, precision, max_iter, lr=0.01):\n",
    "     # create initial variables\n",
    "    # right now we only test with the 26 alphabets\n",
    "    from string import ascii_lowercase\n",
    "    import time\n",
    "    import numpy as np\n",
    "\n",
    "    name_ls = iter(ascii_lowercase)\n",
    "\n",
    "    # create initial variables\n",
    "    var_names = []\n",
    "    for i in x0:\n",
    "        name = next(name_ls)\n",
    "        var_names.append(name)\n",
    "\n",
    "    x = np.array(x0)\n",
    "    s = 0 # initialize as 0 works to ensure that s=g in 1st iteration\n",
    "\n",
    "    nums_iteration = 0\n",
    "    val_rec = []\n",
    "    time_rec = []\n",
    "    init_time = time.time()\n",
    "     # initial guess of n = 0.01\n",
    "    n = 0.01\n",
    "    while True:\n",
    "        # recreate new variables with new values\n",
    "        x_var = []\n",
    "        for i, v in enumerate(x):\n",
    "            x_var.append(Variable(var_names[i], v))\n",
    "        # obtain values and jacobian to find delta_f\n",
    "        val_vector = np.array([value.val for value in x_var])\n",
    "        jacobian = np.array([fn(*x_var).der.get(i) for i in var_names])\n",
    "        delta_f = jacobian*val_vector\n",
    "\n",
    "\n",
    "        # update x\n",
    "        old_x = x\n",
    "        x = x - lr*delta_f\n",
    "        print(x)\n",
    "        # threshold stopping condition\n",
    "        if max(abs(x-old_x)) < precision:\n",
    "            return Result(x, val_rec, time_rec, True)\n",
    "\n",
    "        # store history of values\n",
    "        val_rec.append(x)\n",
    "\n",
    "        time_rec.append(time.time()-init_time)\n",
    "\n",
    "        # iteration stopping condition\n",
    "        if nums_iteration >= max_iter:\n",
    "            return Result(x, val_rec    , time_rec, False)\n",
    "        nums_iteration +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_steepestdescent(fn, x0, precision, max_iter):\n",
    "     # create initial variables\n",
    "    # right now we only test with the 26 alphabets\n",
    "    from string import ascii_lowercase\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from scipy.optimize import fmin\n",
    "\n",
    "    name_ls = iter(ascii_lowercase)\n",
    "\n",
    "    # create initial variables\n",
    "    var_names = []\n",
    "    for i in x0:\n",
    "        name = next(name_ls)\n",
    "        var_names.append(name)\n",
    "\n",
    "    x = np.array(x0)\n",
    "    s = 0 # initialize as 0 works to ensure that s=g in 1st iteration\n",
    "\n",
    "    nums_iteration = 0\n",
    "    val_rec = []\n",
    "    time_rec = []\n",
    "    init_time = time.time()\n",
    "     # initial guess of n = 0.01\n",
    "    n = 0.01\n",
    "    while True:\n",
    "        # recreate new variables with new values\n",
    "        x_var = []\n",
    "        for i, v in enumerate(x):\n",
    "            x_var.append(Variable(var_names[i], v))\n",
    "        # obtain values and jacobian to find delta_f\n",
    "        val_vector = np.array([value.val for value in x_var])\n",
    "        jacobian = np.array([fn(x_var).der.get(i) for i in var_names])\n",
    "        delta_f = jacobian*val_vector\n",
    "\n",
    "\n",
    "        find_min = fmin(fn, val_vector-n*delta_f, maxiter = 1, disp=False)\n",
    "        n = (find_min - x)/delta_f\n",
    "\n",
    "        # update x\n",
    "        old_x = x\n",
    "        x = x + n*delta_f\n",
    "\n",
    "        # threshold stopping condition\n",
    "        if max(abs(x-old_x)) < precision:\n",
    "            return Result(x, val_rec, time_rec, True)\n",
    "\n",
    "        # store history of values\n",
    "        val_rec.append(x)\n",
    "\n",
    "        time_rec.append(time.time()-init_time)\n",
    "\n",
    "        # iteration stopping condition\n",
    "        if nums_iteration >= max_iter:\n",
    "            return Result(x, val_rec    , time_rec, False)\n",
    "        nums_iteration +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
