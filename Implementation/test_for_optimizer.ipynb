{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    from Optimizer import minimize\n",
    "    from evaluate import *\n",
    "except:\n",
    "    from Implementation.Optimizer import minimize\n",
    "    from Implementation.evaluate import *\n",
    "\n",
    "try:\n",
    "    sys.path.append('../AutoDiff')\n",
    "    from variables import Variable\n",
    "except:\n",
    "    from AutoDiff.variables import Variable\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=lambda x, y : 100*(y-x**2)**2 + (1-x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0_list = [[-1,1], [0,1], [2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['Conjugate Gradient','Steepest Descend','BFGS','Gradient Descend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-f81150183caa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv0\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mv0_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-f81150183caa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv0\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mv0_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\cs207_FinalProject\\Implementation\\Optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, method, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin_steepestdescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m\"BFGS\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin_BFGS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Gradient Descend\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin_gradientdescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\cs207_FinalProject\\Implementation\\Optimizer.py\u001b[0m in \u001b[0;36mmin_BFGS\u001b[1;34m(fn, x0, precision, max_iter, beta, c, alpha_init)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mval_rec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;31m# update hessian approximation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mnew_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\cs207_FinalProject\\Implementation\\Optimizer.py\u001b[0m in \u001b[0;36m_line_search\u001b[1;34m(fn, x, search_direction, grad, beta, c, alpha_init)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_update_hessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapprox_hessian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     return (approx_hessian\n\u001b[0;32m    237\u001b[0m             \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "res={}\n",
    "for model in models:\n",
    "    res[model]=[minimize(f1,v0,method=model) for v0 in v0_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_BFGS=[minimize(f1,v0,method=\"BFGS\") for v0 in v0_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def _get_grad(fn, x, var_names):\n",
    "    variables = [Variable(var_names[idx], x_n) for idx, x_n in enumerate(x)]\n",
    "    out = fn(*variables)\n",
    "    jacobian = out.jacobian()\n",
    "    grad = np.array([jacobian[name] for name in var_names])\n",
    "    return grad\n",
    "def _line_search(fn, x, search_direction, grad, beta = 0.9, c = 0.9, alpha_init = 1):\n",
    "    \"\"\"approximately minimizes f along search_direction\n",
    "    https://en.wikipedia.org/wiki/Backtracking_line_search\n",
    "    \"\"\"\n",
    "    m = search_direction.T.dot(grad)\n",
    "    alpha = alpha_init\n",
    "    while (fn(*(x)) - fn(*(x+alpha*search_direction))) < -c*alpha*m:\n",
    "        alpha = alpha * beta\n",
    "    return alpha\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(self, x, val_rec, time_rec, converge):\n",
    "        \"\"\"Record the optimization results and performance\n",
    "\n",
    "        INPUTS\n",
    "        =======\n",
    "        x array: optimization value, can be either Variable or value. //Or just store the value, since there is no need for its derivatives\n",
    "        val_rec array: stores the function inputs at each iteration, save for plotting the accuracy results.\n",
    "        time_rec array: stores the cumulative time at each iteration.\n",
    "        converge boolean: did the optimization procedure converge\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.val_rec = val_rec\n",
    "        self.time_rec = time_rec\n",
    "        self.converge = converge\n",
    "        # throw warning if not convergent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECISION = 1e-5\n",
    "MAXITER = 1000\n",
    "def BFGS(fn, x0, precision = PRECISION, max_iter = MAXITER, beta = 0.9, c = 0.9, alpha_init = 1, norm=np.inf):\n",
    "    approx_hessian = np.eye(len(x0))\n",
    "    \n",
    "    x = np.array(x0, dtype=np.float)\n",
    "    var_names = ['x'+str(idx) for idx in range(len(x))]\n",
    "    \n",
    "    val_rec = [x.copy()]\n",
    "    time_rec = [0]\n",
    "    init_time = time.time()\n",
    "    \n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        grad_now = _get_grad(fn, x, var_names)\n",
    "        s = np.linalg.solve(approx_hessian,-grad_now)\n",
    "        x+=s\n",
    "        val_rec.append(x.copy())\n",
    "        \n",
    "        # update matrix Hessian\n",
    "        grad1=_get_grad(fn, x, var_names)\n",
    "        y=grad1-grad_now\n",
    "        dH1=np.outer(y,y)/np.dot(y,s)\n",
    "        Hs=np.dot(approx_hessian,s)\n",
    "        dH2=-np.outer(Hs,Hs)/np.dot(Hs,s)\n",
    "        approx_hessian+=dH1+dH2\n",
    "        \n",
    "        time_rec.append(time.time()-init_time)\n",
    "        \n",
    "        if np.linalg.norm(grad1, norm) <= precision:\n",
    "            # reshape val_rec\n",
    "            val_rec = np.array(val_rec)\n",
    "            time_rec = np.array(time_rec)\n",
    "            return Result(x, val_rec, time_rec, True)\n",
    "        \n",
    "    converge = (np.linalg.norm(grad1, norm) <= precision)\n",
    "    return Result(x, np.array(val_rec), time_rec, converge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=BFGS(f1,v0_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00000000e+00,  1.00000000e+00],\n",
       "       [-2.40000000e+03,  6.01000000e+02],\n",
       "       [ 1.86707487e+00,  6.39035624e+02],\n",
       "       [ 3.00287671e+01, -1.34521175e+05],\n",
       "       [ 1.99408493e+00,  1.47850670e+01],\n",
       "       [ 1.99624515e+00,  4.16882903e+00],\n",
       "       [ 1.99628252e+00,  3.98514569e+00],\n",
       "       [ 1.99628252e+00,  3.98514594e+00],\n",
       "       [ 1.99628227e+00,  3.98517986e+00],\n",
       "       [ 1.99628177e+00,  3.98521304e+00],\n",
       "       [ 1.99628002e+00,  3.98527620e+00],\n",
       "       [ 1.99627555e+00,  3.98536365e+00],\n",
       "       [ 1.99626316e+00,  3.98548960e+00],\n",
       "       [ 1.99623048e+00,  3.98563982e+00],\n",
       "       [ 1.99614365e+00,  3.98574921e+00],\n",
       "       [ 1.99591517e+00,  3.98557360e+00],\n",
       "       [ 1.99531420e+00,  3.98436666e+00],\n",
       "       [ 1.99373618e+00,  3.97999697e+00],\n",
       "       [ 1.98957835e+00,  3.96654390e+00],\n",
       "       [ 1.97839965e+00,  3.92722034e+00],\n",
       "       [ 1.94501629e+00,  3.80449334e+00],\n",
       "       [ 1.72918306e+00,  2.99886740e+00],\n",
       "       [ 2.28175930e+00,  5.05408726e+00],\n",
       "       [ 1.68453041e+00,  2.82913198e+00],\n",
       "       [ 1.66870501e+00,  2.77096591e+00],\n",
       "       [ 1.64432099e+00,  2.68515899e+00],\n",
       "       [ 1.60372445e+00,  2.54854241e+00],\n",
       "       [ 1.54927593e+00,  2.37583564e+00],\n",
       "       [ 1.47954620e+00,  2.17342208e+00],\n",
       "       [ 1.41044192e+00,  1.98170664e+00],\n",
       "       [ 1.28832303e+00,  1.63221514e+00],\n",
       "       [ 1.28081554e+00,  1.64455324e+00],\n",
       "       [ 1.20745741e+00,  1.45211179e+00],\n",
       "       [ 1.13180563e+00,  1.26411944e+00],\n",
       "       [ 1.15447130e+00,  1.32862748e+00],\n",
       "       [ 1.12928249e+00,  1.27368358e+00],\n",
       "       [ 1.05517440e+00,  1.10685227e+00],\n",
       "       [ 1.05730331e+00,  1.11646061e+00],\n",
       "       [ 1.02960238e+00,  1.05934009e+00],\n",
       "       [ 1.00699154e+00,  1.01290680e+00],\n",
       "       [ 1.00300580e+00,  1.00608064e+00],\n",
       "       [ 1.00000811e+00,  9.99985626e-01],\n",
       "       [ 1.00001238e+00,  1.00002372e+00],\n",
       "       [ 1.00000002e+00,  1.00000003e+00]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.val_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
