{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation: `AutoDiff`\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [How To Use AutoDiff](#how-to)\n",
    "    - [Installing the Package](#installation)\n",
    "    - [Demo](#demo)\n",
    "2. [Background](#background)\n",
    "4. [Software Organization](#SoftwareOrganization)\n",
    "    - [Directory Structure](#structure)\n",
    "    - [Modules](#modules)\n",
    "    - [Test Suite](#tests)\n",
    "    - [Distribution](#distribution)\n",
    "    - [Installation](#installation)\n",
    "5. [Implementation](#implementation)\n",
    "    - [Core Data Structure](#p1)\n",
    "    - [Major Class](#p2)\n",
    "    - [Method and Name Attributes in AutoDiff Class](#p3)\n",
    "    - [Other Functions](#p4)\n",
    "    - [External Dependences](#p5)\n",
    "6. [Future](#future)\n",
    "\n",
    "<a id=\"introduction\"></a>\n",
    "## Introduction \n",
    "\n",
    "It goes without saying that taking derivatives is an essential operation in numerical methods, optimization, and science. From a computational perspective, however, calculating a derivative can be a difficult.\n",
    "\n",
    "If one uses **finite differences** (i.e. $f'(x) \\approx (f(x+\\epsilon) - f(x))/\\epsilon)$), one needs to choose $\\epsilon$ appropriately. If $\\epsilon$ is too large, the approximation is poor. If $\\epsilon$ is too small, one introduces round-off errors.\n",
    "\n",
    "Alternatively, if one uses **symbolic differentiation** (i.e. an algorithm that produces the derivative as a symbolic function), the problem becomes computationally infeasible when you either have functions with many inputs or want to take high order derivatives. These two scenarios occur often in applications.\n",
    "\n",
    "**Automatic differentiation** overcomes these challenges by providing both quick and accurate derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-to\"></a>\n",
    "## How To Use `autoder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"installation\"></a>\n",
    "### Installing the Package\n",
    "You can use pip to install the test `autoder` package. \n",
    "\n",
    "```\n",
<<<<<<< HEAD
    "pip install -i https://test.pypi.org/simple/autoder\n",
=======
    "pip install -i https://test.pypi.org/simple/ autoder\n",
>>>>>>> e3f60cec1c1180bf08c1b92665aa58f86e75dd4e
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo\"></a>\n",
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the package, first import the `variables` and `AD_numpy` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AutoDiff.variables as v\n",
    "import AutoDiff.AD_numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core object in `autoder` is the `Variable` class. They allow numbers to have both objects and derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable with a name and a value\n",
    "x = v.Variable('x', 3)\n",
    "y = v.Variable('y', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions of `Variable` instances return another `Variable`. Functions such as `sin` and `log` can be found in the `AD_numpy` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable name: f(f(f(x),f(y)),x), Value: 25.14112000805987, Derivatives: {'x': 5.010007503399555, 'y': 8}\n"
     ]
    }
   ],
   "source": [
    "f = x**2+y**2+np.sin(x)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return the partial derivatices, use the `partial_der` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.010007503399555"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.partial_der(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return the jacobian, call the `jacobian` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5.010007503399555, 'y': 8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.jacobian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the functionality of this package, here is a simple implementation of gradient descent to find the minimal parameters of $f=(x+3)^2+(y-5)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters [3, 4]\n",
      "final parameters [-2.9999999899021956, 4.999999998317033]\n"
     ]
    }
   ],
   "source": [
    "# Implementation of gradient descent\n",
    "function = lambda x, y: (x+3)**2+(y-5)**2\n",
    "params = [3,4]\n",
    "print('initial parameters', params)\n",
    "x = v.Variable('x', params[0])\n",
    "y = v.Variable('y', params[1])\n",
    "for epoch in range(1000):\n",
    "    grad = function(x,y).jacobian()\n",
    "    for idx, g in enumerate(grad.values()): \n",
    "        params[idx] = params[idx] - 0.01*g\n",
    "    x = v.Variable('x', params[0])\n",
    "    y = v.Variable('y', params[1])\n",
    "print('final parameters',params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"background\"></a>\n",
    "## Background\n",
    "\n",
    "Automatic differentiation computes derivatives recursively using the chain rule. All functions are either an **\"elementary\" function**, for which we know the derivative, or a composition of elementary functions. To calculate the derivative of a composite function $f(g(x))$, we apply the chain rule as follows:\n",
    "\n",
    "$$\n",
    "\\frac{df}{dx} = \\frac{df}{dg}\\frac{dg}{dx}\n",
    "$$\n",
    "\n",
    "The chain rule can be applied recursively, which we exploit in automatic differentiation. For example, if we have a complex composite function $f(g(h(x)))$, we can compute f'(x) by first calculating\n",
    "\n",
    "$$\n",
    "\\frac{dg}{dx} = \\frac{dg}{dh}\\frac{dh}{dx}\n",
    "$$\n",
    "\n",
    "and then plugging this derivative into \n",
    "\n",
    "$$\n",
    "\\frac{df}{dx} = \\frac{df}{dg}\\frac{dg}{dx}\n",
    "$$\n",
    "\n",
    "This is in fact a simple example of **forward-mode** automatic differentiation. In general, to conduct forward mode automatic differentiation, we represent our function to differentiate as a **computational graph**. The computational graph  captures the inputs and outputs of our elementary functions. In an example that can be found [here](http://www.columbia.edu/~ahd2125/post/2015/12/5/), we can represent $f(x,y)=\\cos(x)\\sin(y)+\\frac{x}{y}$ as \n",
    "\n",
    "![comp-graph](figs/comp_graph_background.png)\n",
    "\n",
    "By computing derivatives recursively using the chain rule from the inputs $x$ and $y$ to the output $f$, we can calculate the derivative over the entire graph.\n",
    "\n",
    "This project will implement only forward-mode automatic differentiation, but as an aside, **reverse-mode automatic differentiation** begins at the output(s) of the computational graph and calculates derivates using the chain rule by traversing the graph backwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"SoftwareOrganization\"></a>\n",
    "## Software Organization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"structure\"></a>\n",
    "### Directory Structure\n",
    "\n",
    "The directory structure will be as follows\n",
    "\n",
    "`\n",
    "AutoDiff\n",
    "|-README.md\n",
    "|-LICENSE\n",
    "|-setup.py\n",
    "|-requirements.txt\n",
    "|-AutoDiff\n",
    "  |-__init__.py\n",
    "  |-variables.py\n",
    "  |-AD_numpy.py\n",
    "  |-user_func.py\n",
    "|-docs\n",
    "  |-documentation.md\n",
    "|-tests\n",
    "  |-__init__.py\n",
    "  |-test_variables.py\n",
    "  |-test_numpy.py\n",
    "  |-test_user_func.py\n",
    "  |-test_derivatives.py\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"modules\"></a>\n",
    "### Modules\n",
    "\n",
    "The `variables` module contains the functionality to define variables that are compatible with automatic differentiation. These variables will be passed to functions in `AD_numpy` or to functions specified by the user with `user_func`.\n",
    "\n",
    "The `AD_numpy` module stores our mathematical functions that will overwrite the typically used numpy package such that the user can use mathematical functions on Variable instances just as they would with numeric values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tests\"></a>\n",
    "### Test Suite\n",
    "\n",
    "We will store our tests in the `tests` module and run them using `TravisCI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"distribution\"></a>\n",
    "### Distribution\n",
    "\n",
    "The package will eventually be distributed on `PyPI`. However, it is currently only available on `test.pypi.org` to indicate that the package is not ready for wide distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation\"></a>\n",
    "\n",
    "### Installation\n",
    "\n",
    "You can use pip to install the test `autoder` package with the following command.\n",
    "\n",
    "```\n",
<<<<<<< HEAD
    "pip install -i https://test.pypi.org/simple/autoder\n",
=======
    "pip install -i https://test.pypi.org/simple/ autoder\n",
>>>>>>> e3f60cec1c1180bf08c1b92665aa58f86e75dd4e
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"implementation\"></a>\n",
    "## Implementation \n",
    "<a id=\"p1\"></a>\n",
    "\n",
    "### Major data structure: Variables and the Computational Graph\n",
    "\n",
    "Our variables will be the nodes in our computational graph. The variables will keep track of the node's value and it's derivative.\n",
    "\n",
    "<a id=\"p2\"></a>\n",
    "### Classes\n",
    "\n",
    "The main class that we will implement is the `Variable` class. All auto-differentiable functions will have inputs and outputs consisting of instances of the `Variable` class. The `Variable` class will be an extension on ordinary python numbers. It will store the derivative of the variable and it's actual value.\n",
    "\n",
    "<a id=\"p3\"></a>\n",
    "### Method and Name Attributes in Variable Class\n",
    "* Name Attributes\n",
    "\n",
    "The `Variable` class will have two main instance variables, the value of the variable instance, and the derivatives of the instance.\n",
    "\n",
    "`Variable.name`: name of the variable. When the user first instantiates a `Variable` instance, it is important that the user sets the name of the variable. This is necessary to keep track of the various variables while we calculate compound functions. Importantly, this will allow us to calculate the partial derivatives with respect to each of the instantiated `Variable` instances correctly.\n",
    "\n",
    "`Variable.val`: value of the variables. The shape is the same as the input variable. \n",
    "\n",
    "`Variable.der`: value of the derivatives. The derivatives are held in a dictionary, with each key corresponding to the names of base Variable instances that we instantiated. The corresponding value pair is the partial derivative of the function with respect to the key.\n",
    "\n",
    "* Methods\n",
    "\n",
    "In order to override the four basic operations of elementary arithmetic (addition, subtraction, multiplication, and division), we use dunder methods within our `Variable` class. The dunder methods return new `Variable` instances with the updated value and derivatives.\n",
    "\n",
    "* Jacobian and Partial Derivatives\n",
    "\n",
    "The two main methods that the user will typically use are `Variable.jacobian()` and `Variabel.partial_der(x)`. The former returns the jacobian of the function that the user calcluated from `Variable` instances. The latter returns the partial derivative with respect to a specific `Variable` instance.\n",
    "\n",
    "<a id=\"p4\"></a>\n",
    "### Other function \n",
    "\n",
    "* Define elementary differentiation function. \n",
    "\n",
    "In order to deal with the other elementary functions (exponential, logarithm, powers, roots, trigonometric functions, inverse trigonometric functions, hyperbolic functions, etc.), we will override the numpy elementary functions such that we can use it for our AutoDiff class. \n",
    "\n",
    ">For example, we will override the `np.sin` function such that if you use it on an `variable` instance `x` at a given value, it will return another `variable` instance with the value of $\\sin(x)$, and the calculated derivative of $\\dot{x}\\cos(x)$ at the given value. Similarly, we will override the `np.exp` function such that if you use it on an `variable` instance `x` at a given value, it will return another `variable` instance with the value of $\\exp(x)$, and the calculated derivative of $\\dot{x}\\exp(x)$ at the given value.\n",
    "\n",
    "To define an auto-differentiable function, the user will pass the expression for the value and derivative to the `user_function` method, which will return a function compatible with `variable` inputs.\n",
    "\n",
    "<a id=\"p5\"></a>\n",
    "### External dependencies \n",
    "\n",
    "The main and only external dependency for our package is the external numpy package. This will be specified in our setup.py file as a dependency that should be installed together with our package. The external numpy package is necessary for our the various mathematical operations necessary for Automatic Differentiation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"future\"></a>\n",
    "## Future\n",
    "<a id=\"p1\"></a>\n",
    "\n",
    "<a id=\"p2\"></a>\n",
    "### Future Implementation\n",
    "Subsequently, we will extend our `AutoDiff` package for vector functions of vectors. The user will be able to construct variables for vectors. This will make it easier for them when they are caluclating vector derivatives. \n",
    "\n",
    "\n",
    "### Project extension: User defined functions\n",
    "\n",
    "In order to ensure that the usage of our own mathematical package is very intuitive, we stick to the various functions that were a part of the original numpy package. However, the user can define their own function as well. For example, imagine if a user wanted to implement the trigonometric secant function. \n",
    "\n",
    "```python\n",
    ">>> sec = lambda x: 1/np.cos(x)\n",
    ">>> sec_der = lambda x: sec(x)*np.tan(x)\n",
    ">>> ad_sec = user_function(sec, sec_der)\n",
    ">>> a = Variable('a', 2)\n",
    ">>> x = ad_sec(a)\n",
    ">>> x.val\n",
    "-2.4029979617223809\n",
    ">>> x.jacobian()\n",
    "5.25064633769958\n",
    "```\n",
    "<a id=\"p3\"></a>\n",
    "### Software Changes\n",
    "\n",
    "Once we implement the functionality allowing users to define functions, we might rewrite all of our own autodifferentiable functions with this method. This will make our test coverage increase and make our code more readable.\n",
    "\n",
    "We will also need to refactor some of our code to account for vector valued inputs.\n",
    "\n",
    "<a id=\"p4\"></a>\n",
    "### Primary Challenges\n",
    "\n",
    "It might be difficult to have our functions handle both scaler and vector inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
>>>>>>> e3f60cec1c1180bf08c1b92665aa58f86e75dd4e
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.5"
=======
   "version": "3.6.7"
>>>>>>> e3f60cec1c1180bf08c1b92665aa58f86e75dd4e
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
